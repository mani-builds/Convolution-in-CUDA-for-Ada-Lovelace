* Two week plan
Start: Jan 31
Week 1: 
Day 1: Implemented 3D convolutions

Day 2: Monitor existing programs using Nsight, then use cuBLAS

Day 3: cutlass, cuTE lecture


* DONE Implement with RAW cuda:
        - Naive conv
        - tiled with shared memory conv

* TODO Implement im2col on GPU(flatten an image by converting it into padded matrix) then use cuBLAS or cuDNN GEMM.
        - [X] Understand im2col
        - [X] Implement on CPU (use NUMPY)
        - [ ] Implement the kernel for GPU and test it

* TODO Use cuDNN's convolution for comparison
- [ ] Do convolution on basic kernel and input matrix

* TODO Implement using WMMA (Leverage Tensor cores)
- [X] Do the basic wmma GEMM
        - Load input image and convert it into a matrix
        - Load the kernel as matrix
        - Can you perform convolution like in Naive conv? (Ans: No, since it's not efficient)

        - Use GEMM (? - if you have used im2col)

- [ ] Implement WMMA convolution as GEMM with im2col

Test: Use MNIST or synthetic data. Verify against NumPy convolve.

Profile: Nsight for bottlenecks (e.g., add kernel fusion if loads are slow).

Make it an executable in linux like a library

Make it importable with pytorch
End: Feb 14

